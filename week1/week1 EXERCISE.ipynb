{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Load environment variables in a file called .env\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Check the key\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code snippet you provided uses a `yield from` statement combined with a set comprehension to yield unique values from a collection of books. Here's a breakdown of what this code does and why:\n",
       "\n",
       "1. **Context**: `yield from` is used in a generator function to delegate part of its operations to another iterable (like a list, set, or another generator). This allows the generator to yield values directly from the iterable.\n",
       "\n",
       "2. **Set Comprehension**: The expression `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension. It constructs a set of authors from the list of `books`. \n",
       "\n",
       "   - `book.get(\"author\")`: This tries to get the \"author\" key from each `book` dictionary. If there's no \"author\" key, this will return `None`.\n",
       "   - The loop iterates over each `book` in the `books` collection.\n",
       "   - The condition `if book.get(\"author\")` ensures that only non-None authors are included in the set. This means that if an author is not specified (for example, if it's `None` or if the key doesn't exist), that entry will be ignored.\n",
       "\n",
       "3. **Why Use a Set?**: The use of a set here is significant because sets automatically handle duplicates. If multiple books have the same author, that author will only appear once in the resulting set.\n",
       "\n",
       "4. **Overall Effect**: The overall logic of the code is to create an iterable of unique author names from a list of books, ignoring any entries that do not have an author. The `yield from` allows this generator to yield each author in turn to the caller, which can be useful for processing or iterating over the unique authors later.\n",
       "\n",
       "### Example\n",
       "\n",
       "Given the following list of books:\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 4\"},\n",
       "    {\"title\": \"Book 5\", \"author\": None},\n",
       "]\n",
       "```\n",
       "\n",
       "The code would yield the authors as:\n",
       "\n",
       "- \"Author A\"\n",
       "- \"Author B\"\n",
       "\n",
       "Note that even though \"Author A\" appears twice, it would only be yielded once because of the set's uniqueness property.\n",
       "\n",
       "### Summary\n",
       "\n",
       "In summary, the code serves to yield a collection of unique author names from a list of book dictionaries while safely ignoring any entries that do not provide a valid author. This is an efficient way to process and gather distinct items from potentially nullable or missing keys in the data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[ {\"role\": \"user\", \"content\": question}],\n",
    "    )\n",
    "result = response.choices[0].message.content\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This piece of code is written in Python. It utilizes the `yield` keyword, which pauses execution until a next iteration of the loop or the function/yield itself returns a value.\n",
       "\n",
       "Here's a breakdown of what this code does:\n",
       "\n",
       "- `{book.get(\"author\") for book in books if book.get(\"author\")}`: \n",
       "  - This is a generator expression that will generate values on-the-fly and remembers state across function calls, just like any other iterable (like lists).\n",
       "  - `for book in books` iterates over each book in the list/collection of books. In this case, 'books' seems to be another variable.\n",
       "  - `if book.get(\"author\")`: This filters out books that do not have an author.\n",
       "\n",
       "- `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`: \n",
       "  - `yield` keyword and the function name 'from'. In this context, it's being used for the concept of \"co-routine\".\n",
       "  - `yield from` statement is called a coalescing function. It yields values from an iterable that would normally be passed as arguments to the current generator.\n",
       "  - The entire expression becomes `co-routine`. This means the code runs in parallel, meaning there's no need to explicitly pass data between separate `yield` points.\n",
       "\n",
       "This piece of code is likely a part of a book reader application. It seems to generate author names iteratively from the list of books which have an author field.\n",
       "\n",
       "Here's some potential use case for this:\n",
       "\n",
       "```python\n",
       "def print_authors(-books, current_book):\n",
       "    for author in yield from {book.get(\"author\") for book in books if book.get(\"author\")}:\n",
       "        print(f\"Author: {author}\")\n",
       "\n",
       "\n",
       "# Create a list of Book objects\n",
       "books = [\n",
       "    {\"title\": \"Book1\", \"author\": \"John Doe\"},\n",
       "    {\"title\": \"Book2\", \"author\": \"\"},\n",
       "    {\"title\": \"Book3\", \"author\": \"Jane Doe\"},\n",
       "]\n",
       "\n",
       "\n",
       "print_authors(books, None)\n",
       "```\n",
       "In the above example, when we yield from a certain expression in `print_authors` function, it yields values on-the-fly, thus not creating memory overhead at every time a list of authors is generated. Also it's very useful for parallel processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[ {\"role\": \"user\", \"content\": question}]\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b21f30-046d-46ca-b44d-f7814b66547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude 3.7 Sonnet and Google gemini-2.0-flash to answer\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989cc13-4a8d-4b71-b248-c0803c8f1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude 3.7 Sonnet to answer\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85f23c-f539-4602-8abb-5a6b2bbc1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Google gemini-2.0-flash to answer\n",
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google has recently released new endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "578fc60a-28b7-48ba-8337-16a4298e9b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --------- 11\n",
      "2 --------- 22\n"
     ]
    }
   ],
   "source": [
    " for g, c in zip([1,2],[11,22,33]):\n",
    "    print(g,\"---------\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ea4da-4cfc-41d9-8e94-f317ee62e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
